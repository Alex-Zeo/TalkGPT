# Cloud Build configuration for TalkGPT
steps:
  # Step 1: Run tests
  - name: 'python:3.10-slim'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        pip install -r requirements.txt
        pip install -r requirements-cli.txt
        python -m pytest tests/ -v --tb=short
    id: 'run-tests'

  # Step 2: Build core application image
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'build'
      - '-t'
      - '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/talkgpt-app:$BUILD_ID'
      - '-t'
      - '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/talkgpt-app:latest'
      - '-f'
      - 'Dockerfile'
      - '.'
    id: 'build-app-image'
    waitFor: ['run-tests']

  # Step 3: Build MCP server image
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'build'
      - '-t'
      - '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/talkgpt-mcp:$BUILD_ID'
      - '-t'
      - '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/talkgpt-mcp:latest'
      - '-f'
      - 'Dockerfile.mcp'
      - '.'
    id: 'build-mcp-image'
    waitFor: ['run-tests']

  # Step 4: Build GPU image
  - name: 'gcr.io/cloud-builders/docker'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        cat > Dockerfile.gpu << 'EOF'
        FROM nvidia/cuda:12.1-devel-ubuntu20.04
        ENV PYTHONDONTWRITEBYTECODE=1 \
            PYTHONUNBUFFERED=1 \
            DEBIAN_FRONTEND=noninteractive \
            CUDA_VISIBLE_DEVICES=all
        RUN apt-get update && apt-get install -y --no-install-recommends \
            python3.10 python3.10-dev python3-pip ffmpeg git wget ca-certificates \
            && rm -rf /var/lib/apt/lists/*
        RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.10 1
        RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1
        WORKDIR /app
        RUN pip install torch==2.4.0+cu121 torchaudio==2.4.0+cu121 -f https://download.pytorch.org/whl/torch_stable.html
        COPY requirements.txt /app/
        RUN pip install --no-cache-dir -r requirements.txt
        RUN pip install ctranslate2==4.5.0
        COPY . /app
        ENV CUDA_VISIBLE_DEVICES=all
        ENV OMP_NUM_THREADS=8
        ENV MKL_NUM_THREADS=8
        ENV KMP_DUPLICATE_LIB_OK=TRUE
        CMD ["python", "-m", "src.cli.main", "--help"]
        EOF
        docker build -t ${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/talkgpt-gpu:$BUILD_ID \
                     -t ${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/talkgpt-gpu:latest \
                     -f Dockerfile.gpu .
    id: 'build-gpu-image'
    waitFor: ['run-tests']

  # Step 5: Push all images
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', '--all-tags', '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/talkgpt-app']
    id: 'push-app-image'
    waitFor: ['build-app-image']

  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', '--all-tags', '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/talkgpt-mcp']
    id: 'push-mcp-image'
    waitFor: ['build-mcp-image']

  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', '--all-tags', '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/talkgpt-gpu']
    id: 'push-gpu-image'
    waitFor: ['build-gpu-image']

  # Step 6: Deploy to GKE
  - name: 'gcr.io/cloud-builders/gke-deploy'
    args:
      - 'run'
      - '--filename=k8s/'
      - '--cluster=${_CLUSTER_NAME}'
      - '--location=${_REGION}'
      - '--namespace=${_NAMESPACE}'
    id: 'deploy-to-gke'
    waitFor: ['push-app-image', 'push-mcp-image', 'push-gpu-image']

  # Step 7: Run smoke tests
  - name: 'gcr.io/cloud-builders/kubectl'
    args:
      - 'run'
      - 'smoke-test'
      - '--image=${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/talkgpt-app:$BUILD_ID'
      - '--rm'
      - '-i'
      - '--restart=Never'
      - '--namespace=${_NAMESPACE}'
      - '--'
      - 'python'
      - '-m'
      - 'src.cli.main'
      - 'status'
      - 'system'
    env:
      - 'CLOUDSDK_COMPUTE_REGION=${_REGION}'
      - 'CLOUDSDK_CONTAINER_CLUSTER=${_CLUSTER_NAME}'
    id: 'smoke-tests'
    waitFor: ['deploy-to-gke']

# Substitutions for flexibility
substitutions:
  _REGION: 'us-central1'
  _REPOSITORY: 'talkgpt-images'
  _CLUSTER_NAME: 'talkgpt-cluster'
  _NAMESPACE: 'talkgpt'

# Build configuration
options:
  machineType: 'E2_HIGHCPU_8'
  logging: CLOUD_LOGGING_ONLY
  env:
    - 'DOCKER_BUILDKIT=1'

# Build timeout (30 minutes)
timeout: 1800s

# Tag images with commit SHA and build ID
tags:
  - 'talkgpt'
  - 'production'

# Artifacts to store
artifacts:
  objects:
    location: 'gs://$PROJECT_ID-build-artifacts'
    paths:
      - 'k8s/*.yaml'
      - 'deploy/*.sh'